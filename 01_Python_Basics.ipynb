{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **#01: Python Basics**\n",
        "- Instructor: [Jaeung Sim](https://jaeungs.github.io/) (University of Connecticut)\n",
        "- Course: OPIM 5671: Data Mining and Time Series Forecasting\n",
        "- Last updated: January 29, 2025"
      ],
      "metadata": {
        "id": "JxjzMe8Qj5Jb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objectives**\n",
        "1. Set your Colab environment using Google Drive.\n",
        "2. Understand basic commands and functions in Python.\n",
        "3. Understand data structure in Python.\n",
        "4. Process a dataset using NumPy and Pandas.\n",
        "\n",
        "**Contents**\n",
        "* Part 1: Colab Environment\n",
        "* Part 2: Basic Commands in Python\n",
        "* Part 3: `NumPy`\n",
        "* Part 4: `Pandas`\n",
        "\n",
        "**References**\n",
        "* [Welcome to Colab!](https://colab.research.google.com/)\n",
        "* [NumPy User Guide](https://numpy.org/doc/stable/user/index.html)\n",
        "* [Pandas Tutorial - W3Schools](https://www.w3schools.com/python/pandas/)\n",
        "* [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/)\n",
        "* [Introduction to Data Science with Python](https://nustat.github.io/DataScience_Intro_python/)"
      ],
      "metadata": {
        "id": "EhMbHph3kCSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1: Colab Environment**\n",
        "* Connect your Google Drive with Colab.\n",
        "* Set your path and load files.\n",
        "* Import and export Python codes."
      ],
      "metadata": {
        "id": "mqN5uTVUhUCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Access to https://colab.research.google.com/\n",
        "\n",
        "Step 2. Start a notebook (File > \"New notebook\" or \"Open notebook\" or \"Upload notebook\")\n",
        "\n",
        "Step 3. Open your Google Drive folder (Colab Notebooks) and check your notebook.\n",
        "\n",
        "Step 4. Set a specific folder in Google Drive as your working directory."
      ],
      "metadata": {
        "id": "l7X_QDoxhVyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FNJCWNnrhYIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your current directory\n",
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "qq50yQBVhZwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your working directory\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/OPIM 5671 (Spring 2025)') # Change the directory to your own"
      ],
      "metadata": {
        "id": "W-t-pD0jhbDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2: Basic Commands in Python**\n",
        "* Execute and revise code cells.\n",
        "* Import and use libraries.\n",
        "* Define a function and calculate numbers.\n"
      ],
      "metadata": {
        "id": "08XnTI3Jhew2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1. Understanding code cells**"
      ],
      "metadata": {
        "id": "f4Xh2K3Jho3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type 'ctrl' + 'enter'\n",
        "print(\"Hello, Huskies!\")"
      ],
      "metadata": {
        "id": "uo6FCHhEhqQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revise the code to print the sentence \"Goodbye, Wolves!\"\n",
        "print(\"Hello, Huskies!\")"
      ],
      "metadata": {
        "id": "sYJ5BYiDhri1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a variable and print its value\n",
        "x = 5\n",
        "y = \"John\"\n",
        "print(x)\n",
        "print(y)\n",
        "print(type(x))\n",
        "print(type(y))"
      ],
      "metadata": {
        "id": "U011H090hs-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only the most recent definition works\n",
        "x = 4       # x is of type int\n",
        "x = \"Sally\" # x is now of type str\n",
        "print(x)\n",
        "x"
      ],
      "metadata": {
        "id": "OuBFRpLthvYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a variable with calculation\n",
        "seconds_in_a_day = 24 * 60 * 60\n",
        "print(seconds_in_a_day)\n",
        "\n",
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "metadata": {
        "id": "STS3RfbRhwNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need indentation to remove an error\n",
        "if 5 > 2:\n",
        "  print(\"Five is greater than two!\") # Space or tab here"
      ],
      "metadata": {
        "id": "524OGZYbhxmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the if...else function with different numbers\n",
        "a = 400\n",
        "b = 200\n",
        "if b > a:\n",
        "  print(\"b is greater than a\")\n",
        "elif a == b:\n",
        "  print(\"a and b are equal\")\n",
        "else:\n",
        "  print(\"a is greater than b\")"
      ],
      "metadata": {
        "id": "RppoJe6ghycn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2. Defining a function**"
      ],
      "metadata": {
        "id": "-acs508thz9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, a function is a block of organized, reusable code that is used to perform a single, related action. Functions provide better modularity for your application and a high degree of code reusability.\n",
        "\n",
        "Defining a function in Python involves a few key components and a basic structure that can be extended based on the complexity of the task the function is designed to perform."
      ],
      "metadata": {
        "id": "G_xDJrsRh2W5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Function Definition:** To define a function, you use the `def` keyword, followed by the function name and parentheses. The general syntax looks like this:\n",
        "\n",
        "```python\n",
        "def function_name(parameters):\n",
        "    # function body\n",
        "```\n",
        "\n",
        "**2. Parameters (Optional):** Inside the parentheses, you can optionally list parameters (also known as arguments) separated by commas. These parameters are inputs that the function can accept, allowing you to pass different values to the function each time you call it.\n",
        "\n",
        "**3. Function Body:** After the colon, the next line starts the block of code known as the function body. This is where you write the code that defines what the function should do. The function body is indented, usually by four spaces. This indentation is essential, as Python uses whitespace to define scope.\n",
        "\n",
        "**4. Return Statement (Optional):** Within the function body, you can optionally include a `return` statement. This statement specifies what value the function should return after it finishes executing. If there is no `return` statement, the function will return `None` by default.\n",
        "\n",
        "**5. Calling a Function:** Once a function is defined, you can call it from other parts of your code using its name followed by parentheses. If the function expects parameters, you provide values within these parentheses."
      ],
      "metadata": {
        "id": "R0AXfaWFh35R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function\n",
        "def greet(name): # Function definition\n",
        "    return f\"Hello, {name}!\" # Function body (`f` formatted string)\n",
        "\n",
        "# Call the function\n",
        "print(greet(\"Huskies\"))"
      ],
      "metadata": {
        "id": "rY0DAvxJh5Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_numbers(a, b):\n",
        "    result = a + b\n",
        "    return result\n",
        "\n",
        "# Calling the function\n",
        "sum_value = add_numbers(5, 3)\n",
        "print(sum_value)"
      ],
      "metadata": {
        "id": "m5bo4aVDh98G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "for i in range(1, 6):\n",
        "    print(f\"Square of {i} is {square(i)}\")"
      ],
      "metadata": {
        "id": "VAebKzK9icC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 3: `NumPy`**"
      ],
      "metadata": {
        "id": "J_VaelaE28-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`NumPy` (**Num**erical **Py**thon) provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these data structures, and it is highly efficient for numerical calculations."
      ],
      "metadata": {
        "id": "A1tXSQii3Gkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NumPy library\n",
        "!pip install numpy # Already installed"
      ],
      "metadata": {
        "id": "tEaDFpVS3CGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import NumPy\n",
        "import numpy as np # Shorten the imported name to np for better readability of code using NumPy"
      ],
      "metadata": {
        "id": "Wf96rmn9_eAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.1. Array**"
      ],
      "metadata": {
        "id": "-FzTtuSHEYNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An **array** is a central data structure of the `NumPy` library. It is a grid of values and it contains information about the raw data, how to locate an element, and how to interpret an element. It has a grid of elements that can be indexed in various ways."
      ],
      "metadata": {
        "id": "Q3XV-WVCEeQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimension of arrays**\n",
        "* One-dimensional: like **a list**\n",
        "* Two-dimensional: like **a table**\n",
        "* Three-dimensional: like **a set of tables**\n",
        "* An arbitrary number of dimensions? Generalized as `ndarray`!\n",
        "\n",
        "<img src=\"https://nustat.github.io/DataScience_Intro_python/Datasets/numpy_image.png\" width=\"1000\" height=\"350\">"
      ],
      "metadata": {
        "id": "j8CVEbxhGAQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most `NumPy` arrays have some restrictions. For instance:\n",
        "* All elements of the array must be of the **same type** of data.\n",
        "* Once created, the **total size** of the array **can't change**.\n",
        "* The shape must be **rectangular**, **not jagged**\n",
        "  * e.g., each row of a two-dimensional array must have the same number of columns."
      ],
      "metadata": {
        "id": "NkxzLh3TJFYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1.1. Creating arrays from scratch**"
      ],
      "metadata": {
        "id": "XyTDuOALE6-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and print example arrays\n",
        "a = np.array([1, 2, 3, 4, 5, 6])\n",
        "A = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print(a[0])\n",
        "print(a[1])\n",
        "print(A[0])\n",
        "print(A[1])"
      ],
      "metadata": {
        "id": "MyB7r945EYw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create various arrays\n",
        "np.zeros(3) # An array filled with 0's"
      ],
      "metadata": {
        "id": "0SgHbkQm6JW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ones(3) # An array filled with 1's"
      ],
      "metadata": {
        "id": "ofrh8vAH6Lqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(5) # An array with a range of elements"
      ],
      "metadata": {
        "id": "Z85mM1zC6MyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1.2. Basic atributes of `numpy` array**"
      ],
      "metadata": {
        "id": "wxDBrcrbKJUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's play with array `a` and `A`\n",
        "a"
      ],
      "metadata": {
        "id": "BfAFs1pj6ZN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "id": "g9E2ke6f6qNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ndim`: shows the number of dimensions (or axes) of the array"
      ],
      "metadata": {
        "id": "0q6J0a_pKSrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a.ndim is\", a.ndim)\n",
        "print(\"A.ndim is\", A.ndim)"
      ],
      "metadata": {
        "id": "pCJ25K-HKNcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`shape`: the size of the array in each dimension. $(m, n)$ for $m$ rows and $n$ columns. The length of the shape tuple is the rank or the number of dimensions `ndim`."
      ],
      "metadata": {
        "id": "MYkw4vogKXnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a.shape is\", a.shape)\n",
        "print(\"A.shape is\", A.shape)"
      ],
      "metadata": {
        "id": "haHEUz1RKX98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`size`: the total number of elements of the array, equivalent to the product of the elements of shape"
      ],
      "metadata": {
        "id": "-oiozU4oKY4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a.size is\", a.size)\n",
        "print(\"A.size is\", A.size)"
      ],
      "metadata": {
        "id": "2uVlDlu-KZJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dtype`: the type of elements in the array\n",
        "\n",
        "* Data type examples are available here: <https://www.geeksforgeeks.org/python-data-types/>\n",
        "\n"
      ],
      "metadata": {
        "id": "9vFyByERKZg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a.dtype is\", a.dtype)\n",
        "print(\"A.dtype is\", A.dtype)"
      ],
      "metadata": {
        "id": "wiRTUnHLKZvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`T`: used to transpose the `NumPy` array"
      ],
      "metadata": {
        "id": "D4k0c5BMKakD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.T"
      ],
      "metadata": {
        "id": "BU0CD-OXKa34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.T"
      ],
      "metadata": {
        "id": "SCSNgYwO7foJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1.3. Array operations**"
      ],
      "metadata": {
        "id": "VofveWGDFJZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add, subtract, multiplicate, and divide arrays. Also, you can use various statistical functions, such as maximum, minimum, sum, mean, product, and standard deviation."
      ],
      "metadata": {
        "id": "CUwWeKWw-jAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two arrays\n",
        "data = np.array([1, 2])\n",
        "ones = np.ones(2, dtype=int) # An array with 1's\n",
        "print(data)\n",
        "print(ones)"
      ],
      "metadata": {
        "id": "k4WKX2WVFJq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add, subtract, multiplicate, and divide arrays\n",
        "print(data + ones)\n",
        "print(data - ones)\n",
        "print(data * data)\n",
        "print(data / data)"
      ],
      "metadata": {
        "id": "OnMQ88Tq-uJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum, minimum, and sum of the elements in 'data' array\n",
        "print(data.max())\n",
        "print(data.min())\n",
        "print(data.sum())"
      ],
      "metadata": {
        "id": "mPNyVY6D-wdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the mean, product, and standard deviation of the elements in 'data' array\n",
        "print(data.mean())\n",
        "print(data.prod())\n",
        "print(data.std())"
      ],
      "metadata": {
        "id": "CoMjLw9a-xPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 4: `Pandas`**"
      ],
      "metadata": {
        "id": "FNIz8YCH208E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Pandas` provides two primary data structures: `Series` (one-dimensional) and `DataFrame` (two-dimensional, like a table). With Pandas, you can easily clean, filter, transform, and visualize data, making it an essential tool for data wrangling in data science and analytics. It is built on top of `NumPy` and integrates seamlessly with other Python libraries."
      ],
      "metadata": {
        "id": "ElmQ4DL798W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this code to import the NumPy and Pandas modules\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EMxiq-lEEghC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.1. Series**\n",
        "\n",
        "Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index."
      ],
      "metadata": {
        "id": "Kh4QuTPl0_Nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Series (`Pandas`) vs. Array (`NumPy`)**\n",
        ">\n",
        "> While Series (`pandas`) and array (`numpy`) may seem similar as one-dimensional arrays, their differences in terms of data handling capabilities, efficiency, and use cases make them suitable for different scenarios in data analysis and scientific computing.\n",
        ">\n",
        "> **1. Use Case:** If you need labeled data, are working with heterogeneous data, or need to align data by labels, `Series` is more suitable. It's also preferable when working with tabular data and when integrating with `pandas` DataFrames.\n",
        ">\n",
        "> **2. Performance:** For numerical operations, especially on large datasets where performance is a concern and where data homogeneity is maintained, `array` (`numpy`) is generally faster and more memory-efficient.\n",
        ">\n",
        "> **3. Functionality:** `Series` provides more functionalities (like handling missing data seamlessly) that are very useful in data analysis and manipulation, especially in data science workflows.\n",
        ">"
      ],
      "metadata": {
        "id": "iLI539w5Sk0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.1. Creating a Series**"
      ],
      "metadata": {
        "id": "62NMx-4i8Rsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series from a list\n",
        "s1 = [1, 7, 2]\n",
        "myvar = pd.Series(s1)\n",
        "print(myvar)"
      ],
      "metadata": {
        "id": "oHlzlcHf2ciA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(myvar[0]) # Call the first item"
      ],
      "metadata": {
        "id": "pIC9cmh73f4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series with labels\n",
        "s1 = [1, 7, 2]\n",
        "myvar = pd.Series(s1, index=[\"x\", \"y\", \"z\"])\n",
        "print(myvar)"
      ],
      "metadata": {
        "id": "8uUrAM6e29Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(myvar[0]) # Call an item with a number\n",
        "print(myvar[\"x\"]) # Call an item with an index"
      ],
      "metadata": {
        "id": "GzkbMtRQ3WCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series from dictionary 'd1'\n",
        "d1 = {\"a\": 0.0, \"b\": 1.0, \"c\": 2.0}\n",
        "pd.Series(d1)"
      ],
      "metadata": {
        "id": "u211b6ui4l3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(d1, index=[\"d\", \"c\", \"b\", \"a\"]) # Change the index order"
      ],
      "metadata": {
        "id": "_-AbEBRk5Nkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series from a dictionary 'calories'\n",
        "calories = {\"day1\": 1420, \"day2\": 1380, \"day3\": 1390}\n",
        "myvar = pd.Series(calories, index = [\"day1\", \"day2\"]) # Insufficient index to store all items\n",
        "print(myvar) # Only first two days will appear"
      ],
      "metadata": {
        "id": "bhWG-T6436Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.2. Exploring Series and Operations**"
      ],
      "metadata": {
        "id": "pE3LWZIA8KLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Series\n",
        "s2 = pd.Series(np.random.randn(5), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
        "print(s2)"
      ],
      "metadata": {
        "id": "7HemLACgBSYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Series is ndarray-like\n",
        "print(s2[0]) # 1st item\n",
        "print(\"----------\")\n",
        "print(s2[:3]) # Before 4th item\n",
        "print(\"----------\")\n",
        "print(s2[s2 > s2.median()]) # Items above median\n",
        "print(\"----------\")\n",
        "print(s2[[1, 2, 3]]) # 2nd - 4th items"
      ],
      "metadata": {
        "id": "QrrhpH0F7qel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Series is dict-like\n",
        "print(s2[\"a\"]) # Item with index \"a\"\n",
        "print(s2[\"e\"])\n",
        "print(\"e\" in s2) # If \"e\" is in series \"s2\"\n",
        "print(\"f\" in s2)\n",
        "print(s2.get(\"e\")) # Item with index \"e\"\n",
        "print(s2.get(\"f\")) # Return 'None'"
      ],
      "metadata": {
        "id": "cueeICL8LZqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorized operations\n",
        "print(s2 + s2)\n",
        "print(\"----------\")\n",
        "print(s2 - s2)\n",
        "print(\"----------\")\n",
        "print(s2 * s2)\n",
        "print(\"----------\")\n",
        "print(s2 / s2)\n",
        "print(\"----------\")\n",
        "print(np.exp(s2)) # Take exponential to each item\n",
        "print(\"----------\")\n",
        "print(s2[1:] + s2[:-1]) # Integrate two sub-series"
      ],
      "metadata": {
        "id": "D5qSrnDgPMgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.2. DataFrame**\n",
        "\n",
        "DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used `pandas` object.\n",
        "\n"
      ],
      "metadata": {
        "id": "vwGOGKk27O4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2.1. Creating and Exploring a DataFrame**"
      ],
      "metadata": {
        "id": "QdRzUc3EQNDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data with two arrays\n",
        "d1 = {\n",
        "  \"calories\": [420, 380, 390, 522],\n",
        "  \"duration\": [50, 40, 45, 36]\n",
        "}\n",
        "\n",
        "# Load data into a DataFrame object\n",
        "df1 = pd.DataFrame(d1)\n",
        "\n",
        "print(df1)"
      ],
      "metadata": {
        "id": "P0eSZCTT7pOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore rows\n",
        "print(df1.loc[0]) # 1st row\n",
        "print('------------')\n",
        "print(df1.loc[[0, 2]]) # 1st and 3rd rows"
      ],
      "metadata": {
        "id": "QHBjkdpOeWzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore rows with named indexes\n",
        "df1 = pd.DataFrame(d1, index = [\"day1\", \"day2\", \"day3\", \"day4\"])\n",
        "\n",
        "df1"
      ],
      "metadata": {
        "id": "rlw0pagTfYCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1.loc[\"day1\"]) # 1st row\n",
        "print('------------')\n",
        "print(df1.loc[0]) # Error message"
      ],
      "metadata": {
        "id": "nUsSQ2ZxfwBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore columns\n",
        "print(df1[\"calories\"]) # 'calories' column\n",
        "print('------------')\n",
        "print(df1[\"duration\"]) # 'duration' column\n",
        "print('------------')\n",
        "print(df1[[\"calories\", \"duration\"]]) # 'calories' and 'duration' column"
      ],
      "metadata": {
        "id": "W-InAh_Oe0vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add columns\n",
        "df1[\"joules\"] = df1[\"calories\"] * 4.184\n",
        "df1[\"hours\"] = df1[\"duration\"] / 60\n",
        "df1[\"minutes\"] = \"minutes\" # See what happens\n",
        "df1[\"seconds\"] = df1[\"duration\"][:2] * 60 # Restrict observations to 2nd row\n",
        "\n",
        "print(df1)\n",
        "print('------------')\n",
        "\n",
        "df1.insert(1, \"order\", np.arange(1, 5)) # DataFrame.insert(loc, column, value, allow_duplicates=_NoDefault.no_default)\n",
        "print(df1)"
      ],
      "metadata": {
        "id": "r7pE7YaLxt6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete columns\n",
        "del df1[\"minutes\"]\n",
        "df1.pop(\"seconds\")\n",
        "\n",
        "df1"
      ],
      "metadata": {
        "id": "Vk3_TKQWx2hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposing\n",
        "print(df1.transpose())\n",
        "print('------------')\n",
        "print(df1[:2].transpose()) # Restrict observations to 2nd row and then transpose"
      ],
      "metadata": {
        "id": "2ENSLK0i8wQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2.2. Merging and Joining**"
      ],
      "metadata": {
        "id": "vTKPSJPJH6CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pandas` provides various facilities for easily combining together `Series` or `DataFrame` with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations. Also, it has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL.\n",
        "\n",
        "This library offers a single function, `merge()`, as the entry point for all standard database join operations between `DataFrame` or named `Series` objects:\n",
        "\n",
        "```python\n",
        "pd.merge(\n",
        "    left,\n",
        "    right,\n",
        "    how=\"inner\",\n",
        "    on=None,\n",
        "    left_on=None,\n",
        "    right_on=None,\n",
        "    left_index=False,\n",
        "    right_index=False,\n",
        "    sort=True,\n",
        "    suffixes=(\"_x\", \"_y\"),\n",
        "    copy=True,\n",
        "    indicator=False,\n",
        "    validate=None,\n",
        ")\n",
        "```\n",
        "\n",
        "* `left`: A DataFrame or named Series object.\n",
        "* `right`: Another DataFrame or named Series object.\n",
        "* `on`: Column or index level names to join on. Must be found in both the left and right DataFrame and/or Series objects. If not passed and `left_index` and `right_index` are `False`, the intersection of the columns in the DataFrames and/or Series will be inferred to be the join keys.\n",
        "* `left_on`: Columns or index levels from the left DataFrame or Series to use as keys. Can either be column names, index level names, or arrays with length equal to the length of the DataFrame or Series.\n",
        "* `right_on`: Columns or index levels from the right DataFrame or Series to use as keys. Can either be column names, index level names, or arrays with length equal to the length of the DataFrame or Series.\n",
        "* `left_index`: If `True`, use the index (row labels) from the left DataFrame or Series as its join key(s). In the case of a DataFrame or Series with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame or Series.\n",
        "* `right_index`: Same usage as `left_index` for the right DataFrame or Series\n",
        "* `how`: One of `'left'`, `'right'`, `'outer'`, `'inner'`, `'cross'`. Defaults to inner.\n",
        "* `sort`: Sort the result DataFrame by the join keys in lexicographical order. Defaults to `True`, setting to `False` will improve performance substantially in many cases.\n",
        "* `suffixes`: A tuple of string suffixes to apply to overlapping columns. Defaults to `('_x', '_y')`.\n",
        "* `copy`: Always copy data (default `True`) from the passed DataFrame or named Series objects, even when reindexing is not necessary. Cannot be avoided in many cases but may improve performance / memory usage. The cases where copying can be avoided are somewhat pathological but this option is provided nonetheless.\n",
        "* `indicator`: Add a column to the output DataFrame called `_merge` with information on the source of each row. `_merge` is Categorical-type and takes on a value of `left_only` for observations whose merge key only appears in `'left'` DataFrame or Series, `right_only` for observations whose merge key only appears in `'right'` DataFrame or Series, and `both` if the observation’s merge key is found in both.\n",
        "* `validate`: string, default `None`. If specified, checks if merge is of specified type.\n",
        "\n",
        "For your information, please refer to the following references:\n",
        "* [**Pandas Merge, Join, Concatenate, and Compare**](https://pandas.pydata.org/docs/user_guide/merging.html)\n",
        "* [**Pandas Codebook**](https://pandas.pydata.org/docs/user_guide/cookbook.html)\n",
        "* [**Pandas Comparison with SQL**](https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html)"
      ],
      "metadata": {
        "id": "B30OmXpEDyNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://media.geeksforgeeks.org/wp-content/uploads/joinimages.png)"
      ],
      "metadata": {
        "id": "fpHxtCAxj__F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Left join with a single key\n",
        "left = pd.DataFrame(\n",
        "    {\n",
        "        \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
        "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
        "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "right = pd.DataFrame(\n",
        "    {\n",
        "        \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
        "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
        "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "result = pd.merge(left, right, how=\"left\", on=\"key\")\n",
        "result"
      ],
      "metadata": {
        "id": "fyY_UjIhH608"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Left join with two keys\n",
        "left = pd.DataFrame(\n",
        "    {\n",
        "        \"key1\": [\"K0\", \"K0\", \"K1\", \"K1\"],\n",
        "        \"key2\": [\"L0\", \"L1\", \"L0\", \"L1\"],\n",
        "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
        "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "right = pd.DataFrame(\n",
        "    {\n",
        "        \"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"],\n",
        "        \"key2\": [\"L0\", \"L0\", \"L0\", \"L0\"],\n",
        "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
        "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "result = pd.merge(left, right, how=\"left\", on=[\"key1\", \"key2\"])\n",
        "result"
      ],
      "metadata": {
        "id": "LrilrMucOfMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Right join with two keys (using 'left' and 'right' defined above)\n",
        "result = pd.merge(left, right, how=\"right\", on=[\"key1\", \"key2\"]) # Set 'right' join\n",
        "result"
      ],
      "metadata": {
        "id": "qJxSYiKsPcIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer join with two keys (using 'left' and 'right' defined above)\n",
        "result = pd.merge(left, right, how=\"outer\", on=[\"key1\", \"key2\"]) # Set 'outer' join\n",
        "result"
      ],
      "metadata": {
        "id": "4XH1_PelO5zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner join with two keys (using 'left' and 'right' defined above)\n",
        "result = pd.merge(left, right, how=\"inner\", on=[\"key1\", \"key2\"]) # Set 'inner' join\n",
        "result"
      ],
      "metadata": {
        "id": "szlHvkHLPoL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer join with two keys + Indicator (using 'left' and 'right' defined above)\n",
        "result = pd.merge(left, right, how=\"outer\", on=[\"key1\", \"key2\"], indicator=\"matched\") # Set 'outer' join + Indicator\n",
        "result"
      ],
      "metadata": {
        "id": "Ds64LjxvQRBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`DataFrame.join()` is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame.\n",
        "\n",
        "```python\n",
        "DataFrame.join(\n",
        "  other,\n",
        "  on=None,\n",
        "  how='left',\n",
        "  lsuffix='',\n",
        "  rsuffix='',\n",
        "  sort=False,\n",
        "  validate=None\n",
        "  )\n",
        "```\n",
        "\n",
        "Please run the following code to see how simple it is to join DataFrames with an index."
      ],
      "metadata": {
        "id": "K2Vf928PRI2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two dataframes sharing an index\n",
        "left = pd.DataFrame(\n",
        "    {\"A\": [\"A0\", \"A1\", \"A2\"], \"B\": [\"B0\", \"B1\", \"B2\"]}, index=[\"K0\", \"K1\", \"K2\"]\n",
        ")\n",
        "\n",
        "\n",
        "right = pd.DataFrame(\n",
        "    {\"C\": [\"C0\", \"C2\", \"C3\"], \"D\": [\"D0\", \"D2\", \"D3\"]}, index=[\"K0\", \"K2\", \"K3\"]\n",
        ")"
      ],
      "metadata": {
        "id": "diNr47EDRpyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The two codes yield the same outcome\n",
        "print(left.join(right))\n",
        "print('------------')\n",
        "print(pd.merge(left, right, how=\"left\", left_index=True, right_index=True))"
      ],
      "metadata": {
        "id": "ALzh8IgjR0e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The two codes yield the same outcome\n",
        "print(left.join(right, how=\"outer\"))\n",
        "print('------------')\n",
        "print(pd.merge(left, right, how=\"outer\", left_index=True, right_index=True))"
      ],
      "metadata": {
        "id": "r-PxavrBSsPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GroupBy**\n",
        "\n",
        "A `groupby()` operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups.\n",
        "\n",
        "```python\n",
        "DataFrame.groupby(\n",
        "  by=None,\n",
        "  axis=0,\n",
        "  level=None,\n",
        "  as_index=True,\n",
        "  sort=True,\n",
        "  group_keys=_NoDefault.no_default,\n",
        "  squeeze=_NoDefault.no_default,\n",
        "  observed=False,\n",
        "  dropna=True\n",
        "  )\n",
        "```\n",
        "\n",
        "Please refer to [**pandas.DataFrame.groupby**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) for details of syntax."
      ],
      "metadata": {
        "id": "p9SqNOTEGfJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the code to create a dataframe (24 rows x 6 columns)\n",
        "import datetime\n",
        "\n",
        "df3 = pd.DataFrame(\n",
        "    {\n",
        "        \"Z\": [1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,7,7,7,8,8,8],\n",
        "        \"A\": [\"one\", \"one\", \"two\", \"three\"] * 6,\n",
        "        \"B\": [\"a\", \"b\", \"c\"] * 8,\n",
        "        \"C\": [\"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"bar\"] * 4,\n",
        "        \"D\": np.random.randn(24),\n",
        "        \"E\": np.random.randn(24),\n",
        "        \"F\": [datetime.datetime(2024, i, 1) for i in range(1, 13)]\n",
        "        + [datetime.datetime(2024, i, 15) for i in range(1, 13)],\n",
        "    }\n",
        ")\n",
        "print(df3)"
      ],
      "metadata": {
        "id": "Vj1XahQPmxdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Briefly explore 'df3'\n",
        "df3.head(5)"
      ],
      "metadata": {
        "id": "IC4T4XnoGot7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply 'groupby' (worked in 2024 but not yielding errors now)\n",
        "print(df3.groupby([\"A\"]).mean()) # Mean by A\n",
        "print('------------')\n",
        "print(df3.groupby([\"A\", \"B\"]).mean()) # Mean by (A x B) combination\n",
        "print('------------')\n",
        "print(df3.groupby([\"A\", \"B\"]).sum()) # Sum by (A x B) combination"
      ],
      "metadata": {
        "id": "xSneeXnmGyaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply 'groupby' (revised in Jan 24, 2025)\n",
        "print(df3.groupby([\"A\"]).mean([\"D\", \"E\", \"F\"])) # Mean by A\n",
        "print('------------')\n",
        "print(df3.groupby([\"A\", \"B\"]).mean([\"D\", \"E\", \"F\"])) # Mean by (A x B) combination\n",
        "print('------------')\n",
        "print(df3.groupby([\"A\", \"B\"]).sum([\"D\", \"E\", \"F\"])) # Sum by (A x B) combination"
      ],
      "metadata": {
        "id": "U4DADlr6nDol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}